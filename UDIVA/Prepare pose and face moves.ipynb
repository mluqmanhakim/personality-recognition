{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ed805af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import h5py\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62a7ee85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_landmarks(task, session, participant, subset):\n",
    "    data_path = f'/nas/project_data/B1_Behavior/hakim/UDIVA/annotation/{subset}'\n",
    "    annotation_path = os.path.join(data_path, task, session, participant, 'annotations_raw.hdf5')\n",
    "    \n",
    "    landmarks = []\n",
    "    with h5py.File(annotation_path, \"r\") as f:\n",
    "        for frame in f.keys():\n",
    "            try:\n",
    "                landmark = f[frame]['face']['landmarks'][()]\n",
    "                landmarks.append(landmark)\n",
    "            except KeyError:\n",
    "                landmarks.append(None)\n",
    "        f.close()\n",
    "    return landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57dbea01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mid_landmarks(landmarks):\n",
    "    mid_landmarks = []\n",
    "    for landmark in landmarks:\n",
    "        mid_landmark = [0, 0]\n",
    "        if landmark is not None:\n",
    "            mid_landmark[0] = landmark[0,:].mean()\n",
    "            mid_landmark[1] = landmark[1,:].mean()\n",
    "        mid_landmarks.append(np.array(mid_landmark))\n",
    "    return mid_landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c8d98f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_face_moves(mid_landmarks):\n",
    "    face_moves = []\n",
    "#     the first move is zero\n",
    "    face_moves.append(np.array([0,0]))\n",
    "    for i in range(len(mid_landmarks)-1):\n",
    "        move = mid_landmarks[i+1] - mid_landmarks[i]\n",
    "        face_moves.append(move)\n",
    "    return face_moves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7127833d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_pose_face_moves(out_3ddfa, face_moves):\n",
    "    pose_face_moves = []\n",
    "    for i in range (len(face_moves)):\n",
    "        com = []\n",
    "        if out_3ddfa[i] is not None:\n",
    "            com = list(out_3ddfa[i]['pose']) + list(face_moves[i])\n",
    "        else:\n",
    "            com = [0,0,0] + list(face_moves[i])\n",
    "        pose_face_moves.append(com)\n",
    "    return np.array(pose_face_moves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8cc78423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6944, 5)\n",
      "(6944, 5)\n"
     ]
    }
   ],
   "source": [
    "subset = 'test'\n",
    "# tasks = ['animals', 'ghost', 'lego', 'talk']\n",
    "tasks = ['lego']\n",
    "\n",
    "annotation_dir = f'/nas/project_data/B1_Behavior/hakim/UDIVA/annotation/{subset}'\n",
    "output_3ddfa_dir = f'/nas/project_data/B1_Behavior/hakim/UDIVA/3DDFA/{subset}'\n",
    "output_dir = f'/nas/project_data/B1_Behavior/hakim/UDIVA/pose_face_moves/{subset}'\n",
    "\n",
    "for task in tasks:\n",
    "    anno_path = os.path.join(annotation_dir, task)\n",
    "    \n",
    "    for session in os.listdir(anno_path):\n",
    "        session_path = os.path.join(anno_path, session)\n",
    "    \n",
    "        for par in os.listdir(session_path):\n",
    "            file_name = task + '_' + session + '_' + par[:3]\n",
    "            out_name = file_name + '.npy'\n",
    "            out_path = os.path.join(output_dir, out_name)\n",
    "            out_3ddfa_name = file_name + '.pickle'\n",
    "            out_3ddfa_path = os.path.join(output_3ddfa_dir, out_3ddfa_name)\n",
    "            \n",
    "            if (task == 'talk' and session == '188189' and par == 'FC1_T'):\n",
    "                continue\n",
    "                \n",
    "            if (os.path.exists(out_path)):\n",
    "                continue\n",
    "            \n",
    "            with open(out_3ddfa_path, 'rb') as f:\n",
    "                out_3ddfa = pickle.load(f, encoding='latin1')\n",
    "            \n",
    "            landmarks = get_landmarks(task, session, par, subset)\n",
    "            mid_landmarks = get_mid_landmarks(landmarks)\n",
    "            face_moves = get_face_moves(mid_landmarks)\n",
    "            \n",
    "            assert len(out_3ddfa) == len(face_moves)\n",
    "            \n",
    "            pose_face_moves = combine_pose_face_moves(out_3ddfa, face_moves)\n",
    "                        \n",
    "#             with open(out_path, 'wb') as f:\n",
    "#                 np.save(f, pose_face_moves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89e06b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "18b1262f",
   "metadata": {},
   "source": [
    "# Check annotation file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "785847c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = '/nas/project_data/B1_Behavior/hakim/UDIVA/annotation/val/ghost/001080/FC1_G/annotations_raw.hdf5'\n",
    "\n",
    "with h5py.File(p, \"r\") as f:\n",
    "    for frame in f.keys():\n",
    "        try:\n",
    "            hand = f[frame]['hands']['left']['landmarks'][()]\n",
    "            body = f[frame]['body']['landmarks'][()]\n",
    "            face = f[frame]['face']['landmarks'][()]\n",
    "        except KeyError:\n",
    "            continue\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90784c31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
