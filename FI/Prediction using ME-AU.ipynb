{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec68dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import logging\n",
    "from model.MEFL import MEFARG\n",
    "from dataset import *\n",
    "from utils import *\n",
    "from conf import get_config,set_logger,set_outdir,set_env\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from facenet_pytorch import MTCNN\n",
    "import pickle\n",
    "import time\n",
    "import pandas as pd\n",
    "from face_alignment import face_alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c7681f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.randn(1,3,224,224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1f3e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_frames(video_path, frames_path):\n",
    "    command = \"/home/luqman/ffmpeg/ffmpeg-git-20220622-amd64-static/ffmpeg -loglevel warning -t 15 -i \" + video_path + \" -r:v 30 -frames:v 450 \" + os.path.join(frames_path, \"%d.png\") \n",
    "    os.system(command)\n",
    "\n",
    "def delete_dir(path):\n",
    "    command = \"rm -r \" + path\n",
    "    os.system(command)\n",
    "\n",
    "def generate_aligned_frames(input_dir, output_dir, mtcnn_output):\n",
    "    for i, landmark in enumerate(mtcnn_output['landmarks']):\n",
    "        filename = str(i+1) + \".png\"\n",
    "        in_img_path = os.path.join(input_dir, filename)\n",
    "        out_img_path = os.path.join(output_dir, filename)\n",
    "\n",
    "        if (landmark is None):\n",
    "            continue\n",
    "        else:\n",
    "            landmark = landmark[0]        \n",
    "            img = cv2.cvtColor(cv2.imread(in_img_path), cv2.COLOR_BGR2RGB)\n",
    "            aligned_img = face_alignment(img, landmark)\n",
    "            img = Image.fromarray(aligned_img)\n",
    "            img.save(out_img_path)\n",
    "            \n",
    "def run_mtcnn(frames_path, batch_size=32):\n",
    "    mtcnn = MTCNN(keep_all=True, device='cuda:1')\n",
    "    frames = []\n",
    "    landmarks = []\n",
    "    frames_count = len([x for x in os.listdir(frames_path)])\n",
    "    \n",
    "    for i in range(1, frames_count+1):\n",
    "        filename = str(i) + '.png'\n",
    "        img_path = os.path.join(frames_path, filename)\n",
    "        img = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)\n",
    "        frame = Image.fromarray(img)\n",
    "        frames.append(frame)\n",
    "\n",
    "        if (len(frames) == batch_size or i == frames_count):\n",
    "            _, _, batch_landmarks = mtcnn.detect(frames, landmarks=True)\n",
    "            landmarks.extend(batch_landmarks)\n",
    "            frames = []\n",
    "\n",
    "    output = {'landmarks': landmarks}\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3a6e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_action_unit(inputs):\n",
    "    net = MEFARG(num_classes=12, backbone=\"swin_transformer_base\")\n",
    "    net_fold1 = load_state_dict(net, \"/nas/project_data/B1_Behavior/hakim/ME-GraphAU/pretrained/swin/MEFARG_swin_base_BP4D_fold1.pth\")\n",
    "    net_fold2 = load_state_dict(net, \"/nas/project_data/B1_Behavior/hakim/ME-GraphAU/pretrained/swin/MEFARG_swin_base_BP4D_fold2.pth\")\n",
    "    net_fold3 = load_state_dict(net, \"/nas/project_data/B1_Behavior/hakim/ME-GraphAU/pretrained/swin/MEFARG_swin_base_BP4D_fold3.pth\")\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        net_fold1 = nn.DataParallel(net_fold1, device_ids = [1,0]).cuda(device=1)\n",
    "        net_fold2 = nn.DataParallel(net_fold2, device_ids = [1,0]).cuda(device=1)\n",
    "        net_fold3 = nn.DataParallel(net_fold3, device_ids = [1,0]).cuda(device=1)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs_fold1, _ = net_fold1(inputs)\n",
    "        outputs_fold2, _ = net_fold2(inputs)\n",
    "        outputs_fold3, _ = net_fold3(inputs)\n",
    "    outputs = (outputs_fold1 + outputs_fold2 + outputs_fold3) / 3\n",
    "    return outputs\n",
    "\n",
    "def make_prediction(input_dir, predictions_dir, mtcnn_output, batch_size=32):\n",
    "    predictions = []\n",
    "    frames = []\n",
    "    \n",
    "    for i in range(len(mtcnn_output['landmarks'])):\n",
    "        if (mtcnn_output['landmarks'][i] is not None): \n",
    "            filename = str(i+1) + \".png\"\n",
    "            img_path = os.path.join(input_dir, filename)        \n",
    "            img = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)\n",
    "            frames.append(img)  \n",
    "        \n",
    "        if (len(frames) == batch_size or i == len(mtcnn_output['landmarks']) - 1):\n",
    "            print(i)\n",
    "            inputs = np.array(frames)\n",
    "            inputs = torch.tensor(inputs, dtype=torch.float32).cuda(device=1)\n",
    "            inputs = inputs.permute(0,3,1,2)\n",
    "            batch_predictions = predict_action_unit(inputs)\n",
    "            predictions.extend(batch_predictions.cpu().numpy())\n",
    "            frames = []\n",
    "            \n",
    "    predictions = np.array(predictions)\n",
    "    out_filename = input_dir.rsplit(\"/\")[-1] + \".npy\"\n",
    "    out_path = os.path.join(predictions_dir, out_filename)\n",
    "    with open(out_path, 'wb') as f:\n",
    "        np.save(f, predictions)\n",
    "    print(f'Prediction: {out_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917613a1",
   "metadata": {},
   "source": [
    "# End-to-end process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e74dedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "video_dir = '/nas/database/Big5/valid'\n",
    "frames_dir = \"/nas/project_data/B1_Behavior/hakim/FI/frames/val\"\n",
    "aligned_frames_dir = '/nas/project_data/B1_Behavior/hakim/FI/frames_aligned/val'\n",
    "predictions_dir = '/nas/project_data/B1_Behavior/hakim/FI/predictions/val'\n",
    "annotation_path = '/nas/database/Big5/gt/annotation_validation.pkl'\n",
    "\n",
    "with open(annotation_path, 'rb') as f:\n",
    "    annotation = pickle.load(f, encoding='latin1')\n",
    "videos = list(annotation['extraversion'].keys())\n",
    "\n",
    "for i, video in enumerate(videos):\n",
    "    if (i == 10):\n",
    "        break\n",
    "    print(f'Processing {i} {video}')\n",
    "    video_path = os.path.join(video_dir, video)\n",
    "    video_name = video.rsplit(\".\")[0] + \".\" + video.rsplit(\".\")[1]\n",
    "    frames_path = os.path.join(frames_dir, video_name)\n",
    "    aligned_frames_path = os.path.join(aligned_frames_dir, video_name)\n",
    "    os.makedirs(frames_path, exist_ok=True)\n",
    "    os.makedirs(aligned_frames_path, exist_ok=True)\n",
    "    convert_to_frames(video_path, frames_path)\n",
    "    mtcnn_output = run_mtcnn(frames_path, batch_size=128)\n",
    "    generate_aligned_frames(frames_path, aligned_frames_path, mtcnn_output)\n",
    "    make_prediction(aligned_frames_path, predictions_dir, mtcnn_output, batch_size=128)\n",
    "    delete_dir(frames_path)\n",
    "    delete_dir(aligned_frames_path)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fc9d25",
   "metadata": {},
   "source": [
    "# Check progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878c80f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ec384b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = '/nas/project_data/B1_Behavior/hakim/FI/frames_aligned/train/rtEASqA8_WE.000'\n",
    "counter = 0\n",
    "for f in os.listdir(DIR):\n",
    "    counter += 1\n",
    "print(f'{counter}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836023f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/nas/project_data/B1_Behavior/hakim/FI/predictions/test/evrzg3Pzyc0.005.mp4.pickle'\n",
    "output = pickle.load(open(path, \"rb\"))\n",
    "len(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3bae45f",
   "metadata": {},
   "source": [
    "# Run only one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf40867a",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_path = '/nas/project_data/B1_Behavior/hakim/FI/frames/train/rtEASqA8_WE.000'\n",
    "aligned_frames_dir = '/nas/project_data/B1_Behavior/hakim/FI/frames_aligned/train'\n",
    "predictions_dir = '/nas/project_data/B1_Behavior/hakim/FI/predictions/train'\n",
    "video_name = 'evrzg3Pzyc0.005.mp4'\n",
    "aligned_frames_path = os.path.join(aligned_frames_dir, video_name)\n",
    "os.makedirs(aligned_frames_path, exist_ok=True)\n",
    "\n",
    "mtcnn_output = run_mtcnn(frames_path, batch_size=128)\n",
    "# generate_aligned_frames(frames_path, aligned_frames_path, mtcnn_output)\n",
    "# make_prediction(aligned_frames_path, predictions_dir, mtcnn_output, batch_size=128)\n",
    "# delete_dir(aligned_frames_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afe95ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_prediction(aligned_frames_path, predictions_dir, mtcnn_output, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa983eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
